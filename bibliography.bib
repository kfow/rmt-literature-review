% Key Sources!

@inproceedings{Zamani:2016:EQL:2970398.2970405,
 author = {Zamani, Hamed and Croft, W. Bruce},
 title = {Embedding-based Query Language Models},
 booktitle = {Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval},
 series = {ICTIR '16},
 year = {2016},
 isbn = {978-1-4503-4497-5},
 location = {Newark, Delaware, USA},
 pages = {147--156},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2970398.2970405},
 doi = {10.1145/2970398.2970405},
 acmid = {2970405},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {language models, pseudo-relevance feedback, query expansion, word embedding},
}

@inproceedings{Zamani:2017:RWE:3077136.3080831,
 author = {Zamani, Hamed and Croft, W. Bruce},
 title = {Relevance-based Word Embedding},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 location = {Shinjuku, Tokyo, Japan},
 pages = {505--514},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3077136.3080831},
 doi = {10.1145/3077136.3080831},
 acmid = {3080831},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {embedding vector, neural network, query classification, query expansion, word representation},
}

@inproceedings{zuccon2015integrating,
  title={Integrating and evaluating neural word embeddings in information retrieval},
  author={Zuccon, Guido and Koopman, Bevan and Bruza, Peter and Azzopardi, Leif},
  booktitle={Proceedings of the 20th Australasian Document Computing Symposium},
  pages={12},
  year={2015},
  organization={ACM}
}

@Inbook{McDonald2017,
author="McDonald, Graham
and Macdonald, Craig
and Ounis, Iadh",
editor="Jose, Joemon M
and Hauff, Claudia
and Alt{\i}ngovde, Ismail Sengor
and Song, Dawei
and Albakour, Dyaa
and Watt, Stuart
and Tait, John",
title="Enhancing Sensitivity Classification with Semantic Features Using Word Embeddings",
bookTitle="Advances in Information Retrieval: 39th European Conference on IR Research, ECIR 2017, Aberdeen, UK, April 8-13, 2017, Proceedings",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="450--463",
abstract="Government documents must be reviewed to identify any sensitive information they may contain, before they can be released to the public. However, traditional paper-based sensitivity review processes are not practical for reviewing born-digital documents. Therefore, there is a timely need for automatic sensitivity classification techniques, to assist the digital sensitivity review process. However, sensitivity is typically a product of the relations between combinations of terms, such as who said what about whom, therefore, automatic sensitivity classification is a difficult task. Vector representations of terms, such as word embeddings, have been shown to be effective at encoding latent term features that preserve semantic relations between terms, which can also be beneficial to sensitivity classification. In this work, we present a thorough evaluation of the effectiveness of semantic word embedding features, along with term and grammatical features, for sensitivity classification. On a test collection of government documents containing real sensitivities, we show that extending text classification with semantic features and additional term n-grams results in significant improvements in classification effectiveness, correctly classifying 9.99{\%} more sensitive documents compared to the text classification baseline.",
isbn="978-3-319-56608-5",
doi="10.1007/978-3-319-56608-5_35",
url="https://doi.org/10.1007/978-3-319-56608-5_35"
}

% Maybe Key Sources
@inproceedings{Ye:2016:WED:2884781.2884862,
 author = {Ye, Xin and Shen, Hui and Ma, Xiao and Bunescu, Razvan and Liu, Chang},
 title = {From Word Embeddings to Document Similarities for Improved Information Retrieval in Software Engineering},
 booktitle = {Proceedings of the 38th International Conference on Software Engineering},
 series = {ICSE '16},
 year = {2016},
 isbn = {978-1-4503-3900-1},
 location = {Austin, Texas},
 pages = {404--415},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2884781.2884862},
 doi = {10.1145/2884781.2884862},
 acmid = {2884862},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {API documents, bug localization, bug reports, skip-gram model, word embeddings},
} 


% Non key sources
@inproceedings{rekabsaz2017word,
  title={Word Embedding Causes Topic Shifting; Exploit Global Context},
  author={Rekabsaz, Navid and Lupu, Mihai and Hanbury, Allan and Zamani, Hamed},
  booktitle={Proc. of SIGIR},
  year={2017}
}